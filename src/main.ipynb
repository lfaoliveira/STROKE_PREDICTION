{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90b20c91",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e86314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Define paths based on environment\n",
    "if Path(\"/kaggle\").exists():\n",
    "    os.environ[\"AMBIENTE\"] = \"KAGGLE\"\n",
    "    os.environ[\"TENSORBOARD_NO_TF\"] = \"1\"\n",
    "\n",
    "    PATH_DATASET = Path(\"/kaggle/working/PROJETO_PESS_DADOS\")\n",
    "    PATH_CODE = PATH_DATASET / \"src\"\n",
    "    PATH_OUTPUT_DIR = PATH_DATASET\n",
    "elif Path(\"/content\").exists():\n",
    "    os.environ[\"AMBIENTE\"] = \"COLAB\"\n",
    "    PATH_DATASET = Path(\"/content/DELETAR\")\n",
    "    PATH_CODE = PATH_DATASET / \"src\"\n",
    "    PATH_OUTPUT_DIR = PATH_DATASET / \"outputs\"\n",
    "else:\n",
    "    os.environ[\"AMBIENTE\"] = \"LOCAL\"\n",
    "    PATH_CODE = Path.cwd()\n",
    "    PATH_DATASET = PATH_CODE.parent\n",
    "    PATH_OUTPUT_DIR = PATH_DATASET / \"outputs\"\n",
    "\n",
    "\n",
    "# Check if installation has been done\n",
    "INSTALL_MARKER = PATH_DATASET / \".install_complete\"\n",
    "try:\n",
    "    if not INSTALL_MARKER.exists():\n",
    "        # Install uv\n",
    "        pass\n",
    "        !pip install uv\n",
    "\n",
    "        # Environment-specific setup\n",
    "        if os.environ[\"AMBIENTE\"] == \"KAGGLE\":\n",
    "            import kaggle_secrets\n",
    "\n",
    "            user_secrets = kaggle_secrets.UserSecretsClient()\n",
    "            github_pat = user_secrets.get_secret(\"GITHUB_PAT\")\n",
    "\n",
    "            os.chdir(\"/kaggle/working\")\n",
    "            os.system(\n",
    "                f\"git clone https://{github_pat}@github.com/lfaoliveira/PROJETO_PESS_DADOS.git\"\n",
    "            )\n",
    "            os.chdir(PATH_DATASET)\n",
    "\n",
    "        elif os.environ[\"AMBIENTE\"] == \"LOCAL\":\n",
    "            os.system(\"git pull origin main\")\n",
    "\n",
    "        # Install dependencies\n",
    "        os.chdir(PATH_DATASET)\n",
    "        os.system(\"uv pip install --requirements pyproject.toml --system\")\n",
    "\n",
    "        if os.environ[\"AMBIENTE\"] == \"KAGGLE\":\n",
    "            os.system(\n",
    "                \"uv pip install --upgrade --force-reinstall --no-cache-dir scipy numpy matplotlib\"\n",
    "            )\n",
    "\n",
    "        # Mark installation as complete\n",
    "        INSTALL_MARKER.touch()\n",
    "        print(\"Installation completed\")\n",
    "    else:\n",
    "        print(\"Installation already completed, skipping...\")\n",
    "\n",
    "    os.chdir(PATH_CODE)\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "except Exception:\n",
    "    print(\"FALHA AO INICIAR NOTEBOOK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef61c38",
   "metadata": {},
   "source": [
    "## Normal training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222276af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "from typing import Literal\n",
    "\n",
    "\n",
    "import gc\n",
    "import mlflow\n",
    "from Models.mlp import MLP\n",
    "from Models.kan import MyKan\n",
    "from lightning import seed_everything, Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from mlflow.pytorch import autolog\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from DataProcesser.datamodule import StrokeDataModule\n",
    "\n",
    "\n",
    "def zip_res(path_sqlite: str, path_mlflow: Path, filename: str):\n",
    "    import shutil\n",
    "\n",
    "    path_sqlite_clean = path_sqlite.replace(\"sqlite:///\", \"\")\n",
    "    print(f\"CWD: {Path.cwd()}\\n\")\n",
    "    PATH_TEMP = Path.cwd() / \"ZIP_TEMP\"\n",
    "    shutil.rmtree(PATH_TEMP, ignore_errors=True)\n",
    "    PATH_TEMP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    shutil.copy(path_sqlite_clean, PATH_TEMP / Path(path_sqlite_clean).name)\n",
    "    shutil.copytree(path_mlflow, PATH_TEMP / path_mlflow.name)\n",
    "\n",
    "    shutil.make_archive(filename.replace(\".zip\", \"\"), \"zip\", PATH_TEMP)\n",
    "    shutil.rmtree(PATH_TEMP)\n",
    "    print(f\"PATH ZIPFILE: {Path(filename).resolve()}\")\n",
    "\n",
    "\n",
    "## -----------------------------COLAR NO KAGGLE------------------\n",
    "def main(CHOICE: str):\n",
    "    ###------SEEDS---------###\n",
    "    RAND_SEED = 42\n",
    "    seed_everything(RAND_SEED)\n",
    "    AMBIENTE = os.environ[\"AMBIENTE\"]\n",
    "    GPU = True if AMBIENTE in [\"KAGGLE\", \"COLAB\"] else False\n",
    "    ## ----------VARIAVEIS TREINO-----------\n",
    "    cpus = os.cpu_count()\n",
    "    WORKERS = cpus if cpus is not None else 1\n",
    "    NUM_DEVICES = 1 if GPU else 1\n",
    "    NUM_NODES = 1\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 2\n",
    "    PATIENCE = 20\n",
    "\n",
    "    #### -------- VARIAVEIS DE LOGGING ------------\n",
    "    EXP_NAME = f\"stroke_{CHOICE}_1\"\n",
    "    RUN_NAME: str | None = None  # nome da RUN: pode ser aleatório ou definido\n",
    "    MLF_TRACK_URI = f\"sqlite:///{PATH_CODE}/mlflow.db\"\n",
    "\n",
    "    mlflow.set_tracking_uri(MLF_TRACK_URI)\n",
    "    mlflow.set_experiment(EXP_NAME)\n",
    "    autolog(log_models=True, checkpoint=True, exclusive=False)\n",
    "\n",
    "    ## ----------VARIAVEIS MODELO-----------\n",
    "    HIDN_DIMS = 32\n",
    "    N_CLASSES = 2\n",
    "    N_LAYERS = 5\n",
    "\n",
    "    datamodule = StrokeDataModule(BATCH_SIZE, WORKERS)\n",
    "\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup(\"fit\")\n",
    "\n",
    "    INPUT_DIMS = datamodule.input_dims or -1\n",
    "    assert INPUT_DIMS > 0\n",
    "    if CHOICE == \"MLP\":\n",
    "        model = MLP(INPUT_DIMS, HIDN_DIMS, N_LAYERS, N_CLASSES)\n",
    "    elif CHOICE == \"KAN\":\n",
    "        model = MyKan(INPUT_DIMS, HIDN_DIMS, N_LAYERS, N_CLASSES)\n",
    "    else:\n",
    "        raise ValueError(\"ESCOLHA DE MODELO ERRADA!\")\n",
    "\n",
    "    _ = model(model.example_input_array)\n",
    "\n",
    "    # loop principal de treinamento\n",
    "    with mlflow.start_run(run_name=RUN_NAME) as run:\n",
    "        active_run_id = run.info.run_id\n",
    "\n",
    "        mlflow_logger = MLFlowLogger(\n",
    "            experiment_name=EXP_NAME,\n",
    "            tracking_uri=MLF_TRACK_URI,\n",
    "            log_model=True,\n",
    "            run_id=active_run_id,\n",
    "        )\n",
    "\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=PATIENCE, mode=\"min\"\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            max_epochs=EPOCHS,\n",
    "            devices=NUM_DEVICES,\n",
    "            accelerator=\"gpu\" if GPU else \"cpu\",\n",
    "            num_nodes=NUM_NODES,\n",
    "            logger=mlflow_logger,\n",
    "            enable_checkpointing=False,\n",
    "            callbacks=[early_stopping],\n",
    "        )\n",
    "        trainer.fit(model, datamodule=datamodule)\n",
    "        mlflow.log_params(dict(model.hparams))\n",
    "\n",
    "    NAME_RESZIP = f\"resultado_kaggle_{EXP_NAME}\"\n",
    "    MLRUNS_FOLDER = Path.cwd() / \"mlruns\"\n",
    "    zip_res(MLF_TRACK_URI, MLRUNS_FOLDER, NAME_RESZIP)\n",
    "    print(\"\\n\", \"=\" * 60)\n",
    "    print(f\"RESULTADOS ZIPADOS {Path(NAME_RESZIP).resolve()}\")\n",
    "    print(\"=\" * 60, \"\\n\")\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        ARQ_TYPE = Literal[\"MLP\", \"KAN\", \"SVM\", \"XGBOOST\"]  ## MODEL ARCHITECTURE\n",
    "        models: list[ARQ_TYPE] = [\"MLP\", \"KAN\"]\n",
    "        for choice in models:\n",
    "            # trains model based on architecture\n",
    "            main(choice)\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    gc.collect()\n",
    "\n",
    "    if os.environ[\"AMBIENTE\"] == \"LOCAL\":\n",
    "        from dashboard import see_model\n",
    "\n",
    "        see_model(PATH_DATASET / \"mlflow.db\", PATH_DATASET / \"..\" / \"mlruns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c1650",
   "metadata": {},
   "source": [
    "## MLFlow's Dashboard (Only works outside of Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbb88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "\n",
    "\n",
    "def see_model(database: pathlib.Path, folder: pathlib.Path):\n",
    "    subprocess.Popen(\n",
    "        [\n",
    "            \"mlflow\",\n",
    "            \"ui\",\n",
    "            \"--backend-store-uri\",\n",
    "            f\"sqlite:///{database}\",\n",
    "            \"--default-artifact-root\",\n",
    "            folder,\n",
    "            \"--host\",\n",
    "            \"127.0.0.1\",\n",
    "            \"--port\",\n",
    "            \"5000\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    PATH_RES_ZIPADO = Path(\n",
    "        \"C:\\\\Users\\\\LUIS_FELIPE\\\\Downloads\\\\resultado_kaggle_stroke_1.zip\"\n",
    "    )\n",
    "    DIR = Path(Path.cwd(), PATH_RES_ZIPADO.name.replace(\".zip\", \"\"))\n",
    "    print(f\"DIR: {DIR}\")\n",
    "    if DIR.exists():\n",
    "        shutil.rmtree(DIR)\n",
    "    DIR.mkdir()\n",
    "    shutil.unpack_archive(PATH_RES_ZIPADO, DIR)\n",
    "\n",
    "    print(\"COMECANDO SUBPROCESSO!\\n\")\n",
    "    see_model(DIR / \"mlflow.db\", DIR / \"mlruns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6528cdda",
   "metadata": {},
   "source": [
    "## Training with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from typing import Literal\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import mlflow\n",
    "from Models.mlp import MLP\n",
    "from lightning import Callback, seed_everything, Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from mlflow.pytorch import autolog\n",
    "from DataProcesser.datamodule import StrokeDataModule\n",
    "import optuna\n",
    "from Models.kan import MyKan\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "# from Models.optimizer import Optimizer\n",
    "\n",
    "\n",
    "def zip_res(\n",
    "    path_sqlite: str, path_mlflow: Path, filename: str, dest_folder: Path | None = None\n",
    "):\n",
    "    import shutil\n",
    "\n",
    "    path_sqlite_clean = path_sqlite.replace(\"sqlite:///\", \"\")\n",
    "    print(f\"CWD: {Path.cwd()}\\n\")\n",
    "    PATH_TEMP = Path.cwd() / \"ZIP_TEMP\"\n",
    "    shutil.rmtree(PATH_TEMP, ignore_errors=True)\n",
    "    PATH_TEMP.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    shutil.copy(path_sqlite_clean, PATH_TEMP / Path(path_sqlite_clean).name)\n",
    "    shutil.copytree(path_mlflow, PATH_TEMP / path_mlflow.name)\n",
    "\n",
    "    # Determine destination folder\n",
    "    if dest_folder is None:\n",
    "        dest_folder = Path.cwd()\n",
    "    else:\n",
    "        dest_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create zip file in destination folder\n",
    "    zip_path = dest_folder / filename.replace(\".zip\", \"\")\n",
    "    shutil.make_archive(str(zip_path), \"zip\", PATH_TEMP)\n",
    "    shutil.rmtree(PATH_TEMP)\n",
    "    print(f\"PATH ZIPFILE: {zip_path.with_suffix('.zip').resolve()}\")\n",
    "\n",
    "\n",
    "def supress_warnings():\n",
    "    import logging\n",
    "\n",
    "    # Suppress specific MLflow warnings\n",
    "    logging.getLogger(\"mlflow.utils.requirements_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "    # Suppress PyTorch Lightning info messages\n",
    "    logging.getLogger(\"pytorch_lightning.utilities.rank_zero\").setLevel(logging.ERROR)\n",
    "\n",
    "    # Suppress Optuna info messages\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "\n",
    "def model_choice(\n",
    "    CHOICE, INPUT_DIMS, HIDN_DIMS, N_LAYERS, N_CLASSES, hyperparameters=None\n",
    "):\n",
    "    if CHOICE == \"MLP\":\n",
    "        model = MLP(\n",
    "            INPUT_DIMS, HIDN_DIMS, N_LAYERS, N_CLASSES, hyperparameters=hyperparameters\n",
    "        )\n",
    "    elif CHOICE == \"KAN\":\n",
    "        model = MyKan(\n",
    "            INPUT_DIMS, HIDN_DIMS, N_LAYERS, N_CLASSES, hyperparameter=hyperparameters\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"ESCOLHA DE MODELO ERRADA!\")\n",
    "    return model\n",
    "\n",
    "\n",
    "## -----------------------------COLAR NO KAGGLE------------------\n",
    "def main(CHOICE: str, MLF_TRACK_URI: str):\n",
    "    ###------SEEDS---------###\n",
    "    RAND_SEED = 42\n",
    "    seed_everything(RAND_SEED)\n",
    "    AMBIENTE = os.environ[\"AMBIENTE\"]\n",
    "    GPU = True if AMBIENTE in [\"KAGGLE\", \"COLAB\"] else False\n",
    "    ## ----------VARIAVEIS TREINO-----------\n",
    "    cpus = os.cpu_count()\n",
    "    WORKERS = cpus if cpus is not None else 1\n",
    "    NUM_DEVICES = 1 if GPU else 1\n",
    "    NUM_NODES = 1\n",
    "    BATCH_SIZE = 16\n",
    "    EPOCHS = 5\n",
    "    TRIALS = 4\n",
    "    PATIENCE = 25\n",
    "    EARLY_STOP = False\n",
    "    PRINT_MODEL_SUMMARY = False\n",
    "\n",
    "    #### -------- VARIAVEIS DE LOGGING ------------\n",
    "    EXP_NAME = f\"stroke_{CHOICE}_1\"\n",
    "    RUN_NAME: str | None = None  # nome da RUN: pode ser aleatório ou definido\n",
    "\n",
    "    mlflow.set_tracking_uri(MLF_TRACK_URI)\n",
    "    mlflow.set_experiment(EXP_NAME)\n",
    "    autolog(log_models=True, checkpoint=True, exclusive=False)\n",
    "\n",
    "    ## ----------VARIAVEIS MODELO-----------\n",
    "    N_CLASSES = 2\n",
    "\n",
    "    datamodule = StrokeDataModule(BATCH_SIZE, WORKERS)\n",
    "\n",
    "    datamodule.prepare_data()\n",
    "    datamodule.setup(\"fit\")\n",
    "\n",
    "    INPUT_DIMS = datamodule.input_dims or -1\n",
    "    assert INPUT_DIMS > 0\n",
    "\n",
    "    # Progress bar for trials\n",
    "    pbar = tqdm(\n",
    "        total=TRIALS,\n",
    "        desc=f\"Optuna Trials ({CHOICE})\",\n",
    "        position=0,\n",
    "        leave=True,\n",
    "        colour=\"green\",\n",
    "    )\n",
    "\n",
    "    # loop principal de treinamento\n",
    "    def objective(trial: optuna.Trial):\n",
    "        # Suggest hyperparameters\n",
    "        hidn_dims = trial.suggest_int(\"hidn_dims\", 16, 256, step=16)\n",
    "        n_layers = trial.suggest_int(\"n_layers\", 4, 12)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
    "\n",
    "        # Recreate dataloaders with trial batch_size\n",
    "        train_loader, val_loader = (\n",
    "            datamodule.train_dataloader(batch_size),\n",
    "            datamodule.val_dataloader(batch_size),\n",
    "        )\n",
    "        # model hyperparameters\n",
    "        hyperparameters = {\n",
    "            # Taxa de aprendizado (escala logarítmica)\n",
    "            \"lr\": trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True),\n",
    "            # Momentum do otimizador\n",
    "            \"beta0\": trial.suggest_float(\"momentum0\", 0.900, 0.9999),\n",
    "            \"beta1\": trial.suggest_float(\"momentum1\", 0.900, 0.9999),\n",
    "            # Weight decay (regularização L2)\n",
    "            \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-7, 1e-2),\n",
    "            # Épocas de warmup\n",
    "            # \"warmup_epochs\": trial.suggest_float(\"warmup_epochs\", 0.0, 5.0),\n",
    "        }\n",
    "\n",
    "        model = model_choice(\n",
    "            CHOICE,\n",
    "            INPUT_DIMS,\n",
    "            hidn_dims,\n",
    "            n_layers,\n",
    "            N_CLASSES,\n",
    "            hyperparameters=hyperparameters,\n",
    "        )\n",
    "        _ = model(model.example_input_array)\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"trial_{trial.number}\", nested=True) as run:\n",
    "            active_run_id = run.info.run_id\n",
    "\n",
    "            mlflow_logger = MLFlowLogger(\n",
    "                experiment_name=EXP_NAME,\n",
    "                tracking_uri=MLF_TRACK_URI,\n",
    "                log_model=True,\n",
    "                run_id=active_run_id,\n",
    "            )\n",
    "\n",
    "            early_stopping = EarlyStopping(\n",
    "                monitor=\"val_loss\", patience=PATIENCE, mode=\"min\"\n",
    "            )\n",
    "            callbacks: list[Callback] | None = [early_stopping] if EARLY_STOP else None\n",
    "\n",
    "            trainer = Trainer(\n",
    "                max_epochs=EPOCHS,\n",
    "                devices=NUM_DEVICES,\n",
    "                accelerator=\"gpu\" if GPU else \"cpu\",\n",
    "                num_nodes=NUM_NODES,\n",
    "                logger=mlflow_logger,\n",
    "                enable_checkpointing=False,  # must be disabled for mlflow correct logging\n",
    "                enable_model_summary=PRINT_MODEL_SUMMARY,\n",
    "                enable_progress_bar=False,  # Disable PyTorch Lightning progress bar, to avoid log polution\n",
    "                callbacks=callbacks,\n",
    "            )\n",
    "\n",
    "            trainer.fit(\n",
    "                model, train_dataloaders=train_loader, val_dataloaders=val_loader\n",
    "            )\n",
    "            mlflow.log_params(dict(model.hparams))\n",
    "\n",
    "            val_loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix({\"val_loss\": f\"{val_loss:.4f}\", \"trial\": trial.number})\n",
    "\n",
    "            return val_loss\n",
    "\n",
    "    with mlflow.start_run(run_name=RUN_NAME) as parent_run:\n",
    "        study = optuna.create_study(direction=\"minimize\", study_name=f\"{CHOICE}\")\n",
    "        study.optimize(objective, n_trials=TRIALS, gc_after_trial=True)\n",
    "\n",
    "\n",
    "        # Log best parameters\n",
    "        mlflow.log_params(\n",
    "            {\"best_\" + k: v for k, v in study.best_trial.params.items()},\n",
    "            run_id=parent_run.info.run_id,\n",
    "        )\n",
    "\n",
    "        mlflow.log_metric(\n",
    "            \"best_val_loss\",\n",
    "            study.best_trial.value or float(\"inf\"),\n",
    "            run_id=parent_run.info.run_id,\n",
    "        )\n",
    "\n",
    "        print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "        print(\"Best validation loss:\", study.best_trial.value)\n",
    "        best_run_id = study.best_trial.user_attrs.get(\"run_id\")\n",
    "\n",
    "        mlflow.log_params(\n",
    "            {\"best_trial_id\": best_run_id},\n",
    "            run_id=parent_run.info.run_id,\n",
    "        )\n",
    "\n",
    "        # Close progress bar\n",
    "        pbar.close()\n",
    "\n",
    "        # Identify and tag the best run (no rename_run in MLflow Python API)\n",
    "        experiment = mlflow.get_experiment_by_name(EXP_NAME)\n",
    "        if experiment:\n",
    "            runs_df = pd.DataFrame(\n",
    "                mlflow.search_runs(\n",
    "                    experiment_ids=[experiment.experiment_id],\n",
    "                    order_by=[\"metrics.val_loss ASC\"],\n",
    "                )\n",
    "            )\n",
    "            runs_df = runs_df.dropna(subset=[\"metrics.val_loss\"])\n",
    "            if not runs_df.empty:\n",
    "                best_run_id = runs_df.iloc[0].run_id\n",
    "                prefix = os.environ[\"OPTUNA_BEST_RUN_PREFIX\"]\n",
    "                mlflow.MlflowClient().set_tag(\n",
    "                    best_run_id, \"mlflow.runName\", f\"{prefix}_{CHOICE}\"\n",
    "                )\n",
    "            else:\n",
    "                raise ModuleNotFoundError(\"Runs Dataframe empty\\n\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        ARQ_TYPE = Literal[\"MLP\", \"KAN\", \"SVM\", \"XGBOOST\", \"RNDFOREST\", \"LIQUIDNN\"]  ## MODEL ARCHITECTURE\n",
    "        models: list[ARQ_TYPE] = [\"MLP\", \"KAN\"]\n",
    "        MLF_TRACK_URI = f\"sqlite:///{PATH_CODE}/mlflow.db\"\n",
    "\n",
    "        os.environ[\"OPTUNA\"] = \"True\"\n",
    "        os.environ[\"OPTUNA_BEST_RUN_PREFIX\"] = \"best_run\"\n",
    "        \n",
    "        \n",
    "        supress_warnings()\n",
    "        for i, choice in enumerate(models):\n",
    "            # trains model based on architecture\n",
    "            if i > 0:  # Only clear output between models, not at the start\n",
    "                clear_output(wait=True)\n",
    "            main(choice, MLF_TRACK_URI)\n",
    "\n",
    "        NAME_RESZIP = \"resultado_kaggle\"\n",
    "        MLRUNS_FOLDER = PATH_CODE / \"mlruns\"\n",
    "        ZIP_ROOT = (\n",
    "            PATH_DATASET / \"..\" if os.environ[\"AMBIENTE\"] == \"KAGGLE\" else PATH_DATASET\n",
    "        )\n",
    "        zip_res(MLF_TRACK_URI, MLRUNS_FOLDER, NAME_RESZIP, ZIP_ROOT)\n",
    "        print(\"\\n\", \"=\" * 60)\n",
    "        print(f\"RESULTADOS ZIPADOS {Path(NAME_RESZIP).resolve()}\")\n",
    "        print(\"=\" * 60, \"\\n\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"PREMATURELY INTERRUPTING...\\n\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "    if os.environ[\"AMBIENTE\"] == \"LOCAL\":\n",
    "        from dashboard import see_model\n",
    "\n",
    "        see_model(PATH_DATASET / \"mlflow.db\", PATH_DATASET / \"..\" / \"mlruns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb81704",
   "metadata": {},
   "source": [
    "## Final analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from typing import Literal\n",
    "from DataProcesser.graph import train_metrics\n",
    "\n",
    "# Set MLflow tracking URI\n",
    "mlflow.set_tracking_uri(f\"sqlite:///{PATH_CODE}/mlflow.db\")\n",
    "\n",
    "# --------#\n",
    "\n",
    "ARQ_TYPE = Literal[\"MLP\", \"KAN\", \"SVM\", \"XGBOOST\"]  ## MODEL ARCHITECTURE\n",
    "models: list[ARQ_TYPE] = [\"MLP\", \"KAN\"]\n",
    "\n",
    "# Saves directly to env output dir\n",
    "output_dir = PATH_OUTPUT_DIR\n",
    "if os.environ[\"AMBIENTE\"] == \"KAGGLE\":\n",
    "    output_dir = PATH_DATASET.parent\n",
    "\n",
    "compare_df = train_metrics(models, output_dir)\n",
    "compare_df.to_csv(\"./results.csv\")\n",
    "print(compare_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projeto-kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
